{"cells":[{"cell_type":"raw","metadata":{"id":"zoMJmq3boC0e"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XZ08jvT1oC0f"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","def acc_constructor(ind):\n","    # Load accelerometer data\n","    df = pd.read_csv(f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_E4/ACC.csv', skiprows=2)\n","    df.columns = ['acc_x', 'acc_y', 'acc_z']\n","    df[\"datetime\"] = pd.to_datetime(df.index / 32, unit=\"s\", origin=\"2024-01-01\")\n","\n","    # Load activity data\n","    act_df = pd.read_csv(f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_activity.csv', header=0)\n","    act_df.columns = ['act_name', f'S{ind}']\n","    act_df['timedelta'] = pd.to_timedelta(act_df[f'S{ind}'], unit='s')\n","    starting_time = pd.Timestamp('2024-01-01 00:00:00')\n","    act_df['datetime'] = starting_time + act_df['timedelta']\n","\n","    # Assign specific categories using lambda\n","    activity_mapping = {\n","        \"# BASELINE\": 1,\n","        \"# CLEAN_BASELINE\": 2,\n","        '# STAIRS': 3,\n","        '# SOCCER': 4,\n","        '# CYCLING': 5,\n","        '# WALKING': 6,\n","        \"# LUNCH\": 7,\n","        \"# WORKING\": 8,\n","        \"# DRIVING\": 9\n","    }\n","    act_df['activity'] = act_df['act_name'].map(activity_mapping).fillna(0).astype(int)\n","\n","    # Debug: Print unique activities\n","    print(f\"Unique activities in S{ind}: {act_df['act_name'].unique()}\")\n","\n","    # Debug: Print the activity column to check classification\n","    print(f\"Activity classification for S{ind}:\")\n","    print(act_df[['act_name', 'activity']].head(18))\n","\n","    # Assign activity labels to the accelerometer data\n","    for i, row in act_df.iterrows():\n","        start_time = row['datetime']\n","        end_time = act_df.iloc[i + 1]['datetime'] if i < len(act_df) - 1 else pd.Timestamp('2024-01-01 23:59:59')\n","        activity_value = row['activity']\n","        df.loc[(df['datetime'] >= start_time) & (df['datetime'] < end_time), 'activity'] = activity_value\n","\n","    df['activity'] = df['activity'].astype(int)\n","\n","\n","    # Check if the file exists and remove it\n","    output_path = f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_E4/ACC_with_specific_activity.csv'\n","    if os.path.exists(output_path):\n","        os.remove(output_path)\n","\n","    # Save the DataFrame\n","    df.to_csv(output_path, index=False)\n","    print(f\"S{ind} done!\")\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LFzqExZRoC0g"},"outputs":[],"source":["def hr_constructor(ind):\n","    # Load accelerometer data\n","    df = pd.read_csv(f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_E4/HR.csv', skiprows=2)\n","    df.columns = [\"hr\"]\n","    df[\"datetime\"] = pd.to_datetime(df.index, unit=\"s\", origin=\"2024-01-01\")\n","\n","    # Load activity data\n","    act_df = pd.read_csv(f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_activity.csv', header=0)\n","    act_df.columns = ['act_name', f'S{ind}']\n","    act_df['timedelta'] = pd.to_timedelta(act_df[f'S{ind}'], unit='s')\n","    starting_time = pd.Timestamp('2024-01-01 00:00:00')\n","    act_df['datetime'] = starting_time + act_df['timedelta']\n","\n","    # Assign specific categories using lambda\n","    activity_mapping = {\n","        \"# BASELINE\": 1,\n","        \"# CLEAN_BASELINE\": 2,\n","        '# STAIRS': 3,\n","        '# SOCCER': 4,\n","        '# CYCLING': 5,\n","        '# WALKING': 6,\n","        \"# LUNCH\": 7,\n","        \"# WORKING\": 8,\n","        \"# DRIVING\": 9\n","    }\n","    act_df['activity'] = act_df['act_name'].map(activity_mapping).fillna(0).astype(int)\n","\n","    # Debug: Print unique activities\n","    print(f\"Unique activities in S{ind}: {act_df['act_name'].unique()}\")\n","\n","    # Debug: Print the activity column to check classification\n","    print(f\"Activity classification for S{ind}:\")\n","    print(act_df[['act_name', 'activity']].head(18))\n","\n","    # Assign activity labels to the accelerometer data\n","    for i, row in act_df.iterrows():\n","        start_time = row['datetime']\n","        end_time = act_df.iloc[i + 1]['datetime'] if i < len(act_df) - 1 else pd.Timestamp('2024-01-01 23:59:59')\n","        activity_value = row['activity']\n","        df.loc[(df['datetime'] >= start_time) & (df['datetime'] < end_time), 'activity'] = activity_value\n","\n","    df['activity'] = df['activity'].astype(int)\n","\n","\n","    # Check if the file exists and remove it\n","    output_path = f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_E4/HR_with_specific_activity.csv'\n","    if os.path.exists(output_path):\n","        os.remove(output_path)\n","\n","    # Save the DataFrame\n","    df.to_csv(output_path, index=False)\n","    print(f\"S{ind} done!\")\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmCKyfYtoC0h"},"outputs":[],"source":["def bpv_constructor(ind):\n","    # Load accelerometer data\n","    df = pd.read_csv(f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_E4/BVP.csv', skiprows=2)\n","    df.columns = [\"bvp\"]\n","    df[\"datetime\"] = pd.to_datetime(df.index / 64, unit=\"s\", origin=\"2024-01-01\")\n","\n","    # Load activity data\n","    act_df = pd.read_csv(f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_activity.csv', header=0)\n","    act_df.columns = ['act_name', f'S{ind}']\n","    act_df['timedelta'] = pd.to_timedelta(act_df[f'S{ind}'], unit='s')\n","    starting_time = pd.Timestamp('2024-01-01 00:00:00')\n","    act_df['datetime'] = starting_time + act_df['timedelta']\n","\n","    # Assign specific categories using lambda\n","    activity_mapping = {\n","        \"# BASELINE\": 1,\n","        \"# CLEAN_BASELINE\": 2,\n","        '# STAIRS': 3,\n","        '# SOCCER': 4,\n","        '# CYCLING': 5,\n","        '# WALKING': 6,\n","        \"# LUNCH\": 7,\n","        \"# WORKING\": 8,\n","        \"# DRIVING\": 9\n","    }\n","    act_df['activity'] = act_df['act_name'].map(activity_mapping).fillna(0).astype(int)\n","\n","    # Debug: Print unique activities\n","    print(f\"Unique activities in S{ind}: {act_df['act_name'].unique()}\")\n","\n","    # Debug: Print the activity column to check classification\n","    print(f\"Activity classification for S{ind}:\")\n","    print(act_df[['act_name', 'activity']].head(18))\n","\n","    # Assign activity labels to the accelerometer data\n","    for i, row in act_df.iterrows():\n","        start_time = row['datetime']\n","        end_time = act_df.iloc[i + 1]['datetime'] if i < len(act_df) - 1 else pd.Timestamp('2024-01-01 23:59:59')\n","        activity_value = row['activity']\n","        df.loc[(df['datetime'] >= start_time) & (df['datetime'] < end_time), 'activity'] = activity_value\n","\n","    df['activity'] = df['activity'].astype(int)\n","\n","    # Check if the file exists and remove it\n","    output_path = f'HAR/ppg+dalia/data/PPG_FieldStudy/S{ind}/S{ind}_E4/BVP_with_specific_activity.csv'\n","    if os.path.exists(output_path):\n","        os.remove(output_path)\n","\n","    # Save the DataFrame\n","    df.to_csv(output_path, index=False)\n","    print(f\"S{ind} done!\")\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5_LQav1oC0h","outputId":"a012145d-85dd-4c34-f7e0-21055dffaf1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique activities in S1: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S1:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S1 done!\n","Unique activities in S1: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S1:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S1 done!\n","Unique activities in S1: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S1:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S1 done!\n","Unique activities in S2: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S2:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S2 done!\n","Unique activities in S2: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S2:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S2 done!\n","Unique activities in S2: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S2:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S2 done!\n","Unique activities in S3: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S3:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S3 done!\n","Unique activities in S3: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S3:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S3 done!\n","Unique activities in S3: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S3:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S3 done!\n","Unique activities in S4: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S4:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S4 done!\n","Unique activities in S4: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S4:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n","S4 done!\n"]},{"name":"stdout","output_type":"stream","text":["Unique activities in S4: ['# NO_ACTIVITY' '# BASELINE' '# STAIRS' '# SOCCER' '# CYCLING'\n"," '# DRIVING' '# LUNCH' '# WALKING' '# WORKING' '# CLEAN_BASELINE']\n","Activity classification for S4:\n","            act_name  activity\n","0      # NO_ACTIVITY         0\n","1         # BASELINE         1\n","2      # NO_ACTIVITY         0\n","3           # STAIRS         3\n","4      # NO_ACTIVITY         0\n","5           # SOCCER         4\n","6      # NO_ACTIVITY         0\n","7          # CYCLING         5\n","8      # NO_ACTIVITY         0\n","9          # DRIVING         9\n","10     # NO_ACTIVITY         0\n","11           # LUNCH         7\n","12         # WALKING         6\n","13     # NO_ACTIVITY         0\n","14         # WORKING         8\n","15     # NO_ACTIVITY         0\n","16  # CLEAN_BASELINE         2\n","17     # NO_ACTIVITY         0\n"]}],"source":["for i in np.arange(1,16):\n","    acc_constructor(i)\n","    hr_constructor(i)\n","    bpv_constructor(i)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AbSuQ_voC0i"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.12 (conda)","language":"python","name":"py312"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}